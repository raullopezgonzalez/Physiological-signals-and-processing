{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Challenge Naïve Bayes Decisor\n",
    "\n",
    "# PSF-PSP 2019-2020\n",
    "\n",
    "## Grado Ingenería Biomédica - Biomedical Engineering Degree\n",
    "\n",
    "### Universidad Rey Juan Carlos\n",
    "\n",
    "\n",
    "### Authors\n",
    "\n",
    "#### Óscar Barquero Pérez (<oscar.barquero@urjc.es>), Rebeca Goya Esteban (<rebeca.goyaesteban@urjc.es>), Miguel Ángel Cámara Vázquez (<miguelangel.camara@urjc.es>)\n",
    "\n",
    "#### Today\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licencia de Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />Este obra está bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">licencia de Creative Commons Reconocimiento-NoComercial-CompartirIgual 4.0 Internacional</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook\n",
    "\n",
    "In this notebook we are going to develop a very easy Naïve Bayes detector to work on the challenge. Naïve Bayes is a MAP Bayes detector that assumes independence on the features (it is naïve in that sense). Given the circumstances, we are going to use sklearn implementation instead of our own implementation.\n",
    "\n",
    "## Decisor Bayesiano -- Naïve Bayes\n",
    "\n",
    "En este apartado del Lab vamos a *implementar* un decisor Bayesiano. El alumno recordará de las clases de teoría que un decisor Bayesiano MAP, para un caso binacio, tenía la siguiente estructura:\n",
    "\n",
    "$$P(H_1|\\boldsymbol{x}) \\mathop{\\gtrless}^{D_1}_{D_0}P(H_0|\\boldsymbol{x})$$\n",
    "\n",
    "Equivalentemente,\n",
    "\n",
    "$$P(\\boldsymbol{x}|H_1)P(H_1) \\mathop{\\gtrless}^{D_1}_{D_0}P(\\boldsymbol{x}|H_0) P(H_0)$$\n",
    "\n",
    "La dificultad fundamental de este decisor es ser capaz de calcular el likelihood que resulta ser una pdf conjuta condicionada\n",
    "\n",
    "$$p(x_1,\\ldots,x_n|H_i)?????$$\n",
    "\n",
    "En este punto es en el que podemos hacer asunciones simplificando nuestro modelo. En concreto, vamos a hacer una asunción **naïf** sobre la relación entre las características $x_i$. **Vamos a asumir que las pdfs de las características condicionas son indpendientes**. De esta forma:\n",
    "\n",
    "$$p(x_1,\\ldots,x_n|H_i)=p(x_1|H_i)p(x_2|H_i)\\cdots p(x_n|H_i)$$\n",
    "\n",
    "Las pdfs de cada una de las características condiconiadas suelen ser:\n",
    "* Binomial pdf, cuando la característica es binaria (yes or no)\n",
    "* Multinomial pdf, cuando la característica tiene diferentes niveles (categorical variable)\n",
    "* Gaussian pdf, cuando la característica es numérica. Ojo, se pueden realizar transformaciones de la variable para conseguir normalizarla (log, etc)\n",
    "\n",
    "Por ejemplo, supongamos que la pdf de la característica j-ésima es una pdf Gaussiana. De esta forma corresponderá a la siguiente ecuación:\n",
    "\n",
    "$$p(x_j|H_i)= \\frac{1}{\\sqrt{2\\pi\\sigma_j^2}}e ^{-1/2\\frac{(x_j-mu_j)^2}{\\sigma_j^2}}$$\n",
    "\n",
    "En esta pdf hay dos parámetros cuyo valor desconocemos: $\\mu_j$, $\\sigma^2_{j}$.\n",
    "\n",
    "En la fase de training, utilizaremos los datos que tenemos para realizar la estimación de dichos parámetros. Vamos a asumir independiencia en los datos (también), de forma que se pueden utilizar los siguientes estimadores máximos verosimiles:\n",
    "\n",
    "$$\\hat{\\mu}_j = \\frac{1}{N_{train}}\\sum^{N_{train}}_{k=1}x_{k,j}$$\n",
    "$$\\hat{\\sigma}^2_j = \\frac{1}{N_{train}}\\sum^{N_{train}}_{k=1}(x_{k,j}-\\hat{\\mu}_j)^2$$\n",
    "\n",
    "\n",
    "El último parámetro que tenemos que estimar serían las probabilidades a priori para cada clase. Esto debe hacerse también con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "\n",
    "In this step we are going to read our data. Since the aim of the notebook is to show how to use a Naïve Bayes, the features we are going to obtain using signal processing are going to be just the samples in our sequence. In order to keep the number of features small we are going to use onlye the first 50 samples.\n",
    "\n",
    "In the following cells we are going to define a function to extract the samples from a patient in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_one_subject(sub_id):\n",
    "    \"\"\"\n",
    "    Extract first 50 samples from X axis in right foot sensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    #assume we are in the folder with the subjects. \n",
    "    \n",
    "    #Get inside subjet folder\n",
    "    right_foot = np.loadtxt(sub_id+'\\\\PD.txt',skiprows=1)\n",
    "    \n",
    "    signal = right_foot[:,0] #x axis\n",
    "    \n",
    "    return signal[:100]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "#get into de data folder\n",
    "\n",
    "pwd = os.getcwd()\n",
    "path = 'C:\\\\Users\\\\riul0\\\\Desktop\\\\Physiological signals and processing\\\\challeng\\\\Data\\\\Training\\\\'\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "import glob\n",
    "\n",
    "subjects = os.listdir()\n",
    "\n",
    "#subjects.pop(subjects.index('.DS_Store')) #keep this only if your are using mac system\n",
    "\n",
    "print(subjects)\n",
    "\n",
    "X = []\n",
    "\n",
    "for sub in subjects:\n",
    "    \n",
    "    signal = get_features_one_subject(sub)\n",
    "    \n",
    "    X.append(signal)\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that X is going to be our matrix of data:\n",
    " * *Rows*: subjects\n",
    " * *Features*: 50 first samples.\n",
    " \n",
    "Note also that you have to use subjects list to match the class for each subject. Important, subject list is unsorted.\n",
    "\n",
    "We are going to first sort the subjects list before implementing the Naïve Bayes Detector, we have to order also the X matrix (rows exchange) accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 10 11 12 13 14 15 16 17 18 19  2 20 21 22 23 24 25 26 27 28 29  3 30\n",
      " 31 32 33 34 35 36 37 38 39  4 40 41 42 43 44 45 46 47 48 49  5 50 51 52\n",
      " 53 54 55 56 57 58 59  6 60  7  8  9]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54 55 56 57 58 59 60]\n",
      "[0.72001955 0.92396387 1.04339737 1.19983166 1.44950265]\n",
      "[0.72001955 0.92396387 1.04339737 1.19983166 1.44950265]\n",
      "[1.96684025 2.33229933 2.17437078 1.4850388  2.03176323]\n"
     ]
    }
   ],
   "source": [
    "#convert subjects list into an integer numpy array\n",
    "\n",
    "subjects = np.asarray(subjects,dtype = int)\n",
    "\n",
    "print(subjects)\n",
    "\n",
    "#sort subjects and get the sorted index\n",
    "\n",
    "sorted_idx = np.argsort(subjects)\n",
    "\n",
    "subjects_s = subjects[sorted_idx]\n",
    "\n",
    "print(subjects_s)\n",
    "\n",
    "#Sort X matrix, row exchanges\n",
    "\n",
    "X_s = X[sorted_idx,:]\n",
    "\n",
    "print(X_s[-2,:5]) #id 59\n",
    "print(X_s[58,:5]) #id 59 because 0 index is equal a id 1 and so on\n",
    "print(X[0,:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.96684025  2.33229933  2.17437078  1.4850388   2.03176323  1.33381438\n",
      "  0.74213112  0.29864905  0.2613164   0.42963489  0.19909943  0.47547822\n",
      "  0.65118796  0.67530567  0.79753349  1.08456384  1.24923236  1.47868653\n",
      "  1.8547614   2.28140199  2.63765537  2.92819578  2.07678628  0.67664052\n",
      "  0.75447847  0.71689387  0.99024994  1.91589253  0.80978786  1.07909644\n",
      "  0.91989717  0.98850765  1.05654524  0.989506    1.03508108  1.02343782\n",
      "  1.01007346  1.02693072  1.00092083  0.95226873  0.92738134  0.92738134\n",
      "  0.96365429  0.9745363   0.96630292  0.95881796  0.96906888  1.03740952\n",
      "  1.08231901  1.13986972  1.25336543  1.37647619  1.42105328  1.40918164\n",
      "  1.61420329  1.95805362  2.28905332  2.11035807  1.82332478  2.11324198\n",
      "  2.03173954  1.30052276  0.46481567  0.50410835  0.54125859  0.14371019\n",
      "  0.25323915  0.47446006  0.58431152  0.66166653  0.83831015  1.07978016\n",
      "  1.31734483  1.62247887  2.32107131  3.06643867  3.18034273  1.99398737\n",
      "  0.198872   -0.170167    2.52764933  2.31845485  1.46249096  0.91690087\n",
      "  1.26619927  1.03333513  1.30735401  1.13995369  1.06124065  1.04369713\n",
      "  0.99399729  0.94141562  0.93018822  0.99474536  1.03217019  0.99298846\n",
      "  0.94384822  0.9408541   0.97079376  1.01645163]\n"
     ]
    }
   ],
   "source": [
    "print(X_s[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.96684025 2.33229933 2.17437078 ... 0.9408541  0.97079376 1.01645163]\n",
      " [0.67467895 0.91166285 1.22602938 ... 1.43560715 1.52093526 1.60447845]\n",
      " [0.92738124 1.07558264 1.18935339 ... 1.39171796 1.43693507 1.51485382]\n",
      " ...\n",
      " [1.93335427 1.47490327 1.7424887  ... 2.10967291 1.9977247  1.73076263]\n",
      " [0.72001955 0.92396387 1.04339737 ... 1.92241851 2.45879399 2.49247906]\n",
      " [2.25894848 2.2044954  2.2157229  ... 0.37724172 0.61675659 0.25841034]]\n"
     ]
    }
   ],
   "source": [
    "print(X_s[0:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to implement the Naïve Bayes Detector. We are going to need the labels. Since we don't have any other information, we are going to obtain Prior Probabilities from labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#back to the orinigial folder\n",
    "os.chdir(pwd)\n",
    "\n",
    "\n",
    "h = np.loadtxt('C:\\\\Users\\\\riul0\\\\Desktop\\\\Physiological signals and processing\\\\challeng\\\\Training.csv',skiprows=1,delimiter=',')\n",
    "\n",
    "Prior_0 = np.sum(h[:,1]==0)/len(h)\n",
    "Prior_1 = np.sum(h[:,1]==1)/len(h)\n",
    "Prior_2 = np.sum(h[:,1]==2)/len(h)\n",
    "\n",
    "\n",
    "#naive bayes model\n",
    "\n",
    "nb_detector = GaussianNB(priors = [Prior_0,Prior_1,Prior_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have declared the naive bayes detector. Next we need to obtain the mean and std of the gaussians for each feature and for each class. This is make using fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=[0.3333333333333333, 0.3333333333333333, 0.3333333333333333],\n",
       "           var_smoothing=1e-09)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_detector.fit(X_s,h[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1.40\n",
      "Variance: 0.34\n"
     ]
    }
   ],
   "source": [
    "#We can check some parameters\n",
    "#For example, the mean and variance of the Gaussian, for the first class first feature\n",
    "\n",
    "print('Mean: %.2f'%nb_detector.theta_[0,0])\n",
    "print('Variance: %.2f'%nb_detector.sigma_[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our detector implemented, next step is to detect. In this part, which is performed by the predict method, we just get one sample $x*$ and compare the posteriors:\n",
    "\n",
    "$$D_i = max_i \\left(P(H_0|x*), P(H_1|x*), P(H_2|x*)\\right)$$\n",
    "\n",
    "We are going to test for the first subject id=1. For this subject we know that the class is 2. \n",
    "\n",
    "Be aware that we are using the same data we used for training, so results on this data are overfitted, results should be worse for the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection: 2\n",
      "Hypothesis H: 2\n"
     ]
    }
   ],
   "source": [
    "x_1 = X_s[0,:]\n",
    "\n",
    "D = nb_detector.predict(x_1[np.newaxis,:])\n",
    "\n",
    "print('Detection: %d'%D[0])\n",
    "print('Hypothesis H: %d' %h[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the accuracy (probability of get right the class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC = 0.68\n"
     ]
    }
   ],
   "source": [
    "D = nb_detector.predict(X_s)\n",
    "\n",
    "print('ACC = %.2f'%np.mean(D == h[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "This simple method allowed to obtain a pretty decent result, at least in trainig. Let's hope this method won't win the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
